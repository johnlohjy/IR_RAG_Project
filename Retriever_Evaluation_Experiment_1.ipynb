{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc-w2kP7E8ON"
      },
      "source": [
        "# **Retriever Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0A5jt3EE8ON"
      },
      "source": [
        "## **Pre-requisites**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3PuTPVvE8OO"
      },
      "source": [
        "1. You have ran ```Retrieval_Experiment_1``` to get an experiment output\n",
        "2. You have scored all the files inside the experiment output\n",
        "3. You have zipped the experiment output to ```experiment_1_output.zip```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade bitsandbytes langchain langchain-community langchain-huggingface transformers beautifulsoup4 faiss-gpu rank_bm25 lark langchain_groq ragas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHyNvnoLFNlp",
        "outputId": "1d6fb3eb-83b3-49b8-a0d1-1fd3bb748a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWu78iyZE8OO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from ragas.dataset_schema import SingleTurnSample\n",
        "from ragas.metrics import LLMContextRecall\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6FQ5oEBE8OO"
      },
      "source": [
        "## **User Action Required**\n",
        "\n",
        "1. Run the code below to create the ```experiment_outputs``` folder\n",
        "\n",
        "2. Upload ```retriever_evaluation.py```\n",
        "\n",
        "3. Upload the ```experiement_1_output.zip``` file that contains the files you have scored\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1F4JB7sE8OO"
      },
      "outputs": [],
      "source": [
        "experiment_folder = os.path.join(os.getcwd(), 'experiment_outputs', 'experiment_1_output')\n",
        "os.makedirs(experiment_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_Ff8hYoOE8OP",
        "outputId": "e1832930-473b-4a53-ffef-d6ea4cdd501f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-751d6ddb-05b9-434a-9f5d-70bd0d927773\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-751d6ddb-05b9-434a-9f5d-70bd0d927773\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving retriever_evaluation.py to retriever_evaluation.py\n"
          ]
        }
      ],
      "source": [
        "# Upload retriever_evaluation.py\n",
        "files.upload();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload experiment_1_output.zip\n",
        "files.upload();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "afOIBJKVHdS9",
        "outputId": "2bce7de6-c2e4-4bbe-9d78-8a2d1bf4d798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e9bb4fc0-c7ba-4c8d-966a-54c965c606c8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e9bb4fc0-c7ba-4c8d-966a-54c965c606c8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving experiment_1_output.zip to experiment_1_output.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip experiment_1_output.zip -d experiment_outputs/experiment_1_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z95EUaIFoT4",
        "outputId": "4008d69e-fd5d-42f1-87b4-f967ec02931f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  experiment_1_output.zip\n",
            "   creating: experiment_outputs/experiment_1_output/score_relevance/\n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.0_faiss_1.0_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.1_faiss_0.9_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.2_faiss_0.8_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.3_faiss_0.7_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.4_faiss_0.6_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.5_faiss_0.5_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.6_faiss_0.4_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.7_faiss_0.3_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.8_faiss_0.2_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_0.9_faiss_0.1_score_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/score_relevance/hybrid_retriever_bm25_1.0_faiss_0.0_score_relevance.csv  \n",
            "   creating: experiment_outputs/experiment_1_output/binary_relevance/\n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.0_faiss_1.0_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.1_faiss_0.9_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.2_faiss_0.8_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.3_faiss_0.7_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.4_faiss_0.6_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.5_faiss_0.5_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.6_faiss_0.4_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.7_faiss_0.3_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.8_faiss_0.2_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_0.9_faiss_0.1_binary_relevance.csv  \n",
            "  inflating: experiment_outputs/experiment_1_output/binary_relevance/hybrid_retriever_bm25_1.0_faiss_0.0_binary_relevance.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import retriever_evaluation"
      ],
      "metadata": {
        "id": "kwQNsMfWHKQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0irDD7qvE8OP"
      },
      "source": [
        "## **Evaluate Experiment 1: Hybrid/Ensemble Retriever**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDkFntU9E8OP"
      },
      "source": [
        "### **Binary Relevance: Mean Average Precision, Mean Reciprocal Rank**\n",
        "\n",
        "Mean Average Precision:\n",
        "\n",
        "Mean Reciprocal Rank:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLDGk3h5E8OP"
      },
      "outputs": [],
      "source": [
        "experiment_1_binary_relevance_folder = os.path.join(experiment_folder,'binary_relevance')\n",
        "\n",
        "# Initialise dictionaries: { 'bm25_bm25weight_faiss_faiss_weight' = mean average precision}, { 'bm25_bm25weight_faiss_faiss_weight' = mean reciprocal rank}\n",
        "experiment_1_mean_ave_precision_res = {}\n",
        "experiment_1_mean_reciprocal_rank_res = {}\n",
        "# For each bm25 weight and faiss weight combination,\n",
        "# Calculate the mean average precision and mean reciprocal rank over all the queries\n",
        "for f_name in os.listdir(experiment_1_binary_relevance_folder):\n",
        "    f_name_split = f_name.split('_')\n",
        "    bm25_val = f_name_split[3]\n",
        "    faiss_val = f_name_split[5]\n",
        "    fp = os.path.join(experiment_1_binary_relevance_folder, f_name)\n",
        "    full_df = pd.read_csv(fp)\n",
        "    df_split = [group for query, group in full_df.groupby('query')]\n",
        "    relevance_scores = []\n",
        "    for df in df_split:\n",
        "        # TOCHANGE: Assign random 1s or 0s to the relevant col for testing purposes\n",
        "        df['relevant'] = [random.choice([0, 1]) for _ in range(len(df))]\n",
        "        relevance_scores.append(list(df['relevant']))\n",
        "    experiment_1_mean_ave_precision_res[f'bm25_{bm25_val}_faiss_{faiss_val}'] = retriever_evaluation.mean_average_precision(relevance_scores)\n",
        "    experiment_1_mean_reciprocal_rank_res[f'bm25_{bm25_val}_faiss_{faiss_val}'] = retriever_evaluation.mean_reciprocal_rank(relevance_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOSTPYH0E8OP",
        "outputId": "0807d543-4c9a-42c5-e0be-d6a7c6e4aae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best weightage for the mean average precision using binary relevance is:\n",
            "Weightage with bm25: 0.0, faiss: 1.0 with a value of 0.7566468253968255\n"
          ]
        }
      ],
      "source": [
        "max_value_map = max(experiment_1_mean_ave_precision_res.values())\n",
        "best_maps = {key: value for key, value in experiment_1_mean_ave_precision_res.items() if value == max_value_map}\n",
        "print('The best weightage for the mean average precision using binary relevance is:')\n",
        "for k,v in best_maps.items():\n",
        "    bm25_weight = k.split('_')[1]\n",
        "    faiss_weight = k.split('_')[-1]\n",
        "    print(f'Weightage with bm25: {bm25_weight}, faiss: {faiss_weight} with a value of {v}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gujrD8PWE8OP",
        "outputId": "3f9952a4-301e-4f21-e80c-27285eecebbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best weightage for the mean reciprocal rank using binary relevance is:\n",
            "Weightage with bm25: 0.8, faiss: 0.2 with a value of 1.0\n"
          ]
        }
      ],
      "source": [
        "max_value_mrr = max(experiment_1_mean_reciprocal_rank_res.values())\n",
        "best_mrrs = {key: value for key, value in experiment_1_mean_reciprocal_rank_res.items() if value == max_value_mrr}\n",
        "print('The best weightage for the mean reciprocal rank using binary relevance is:')\n",
        "for k,v in best_mrrs.items():\n",
        "    bm25_weight = k.split('_')[1]\n",
        "    faiss_weight = k.split('_')[-1]\n",
        "    print(f'Weightage with bm25: {bm25_weight}, faiss: {faiss_weight} with a value of {v}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPOwixEKE8OP"
      },
      "source": [
        "### **Score Relevance: Mean Normalised Discounted Cumulative Gain**\n",
        "\n",
        "For score relevance, put at k=5 first\n",
        "\n",
        "Mean Normalised Discounted Cumulative Gain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUGJ5kJvE8OP"
      },
      "outputs": [],
      "source": [
        "k = 5\n",
        "experiment_1_score_relevance_folder = os.path.join(experiment_folder,'score_relevance')\n",
        "# Initialise dictionaries: { 'bm25_bm25weight_faiss_faiss_weight' = mean normalised discounted cumulative gain}\n",
        "experiment_1_mean_normalised_discounted_cumulative_gain_res = {}\n",
        "# For each bm25 weight and faiss weight combination,\n",
        "# Calculate the normalised discounted cumulative gain over all the queries\n",
        "for f_name in os.listdir(experiment_1_score_relevance_folder):\n",
        "    f_name_split = f_name.split('_')\n",
        "    bm25_val = f_name_split[3]\n",
        "    faiss_val = f_name_split[5]\n",
        "    fp = os.path.join(experiment_1_score_relevance_folder, f_name)\n",
        "    full_df = pd.read_csv(fp)\n",
        "    df_split = [group for query, group in full_df.groupby('query')]\n",
        "    relevance_scores = []\n",
        "    for df in df_split:\n",
        "        # TOCHANGE: Assign random score between 0 and 5 to the relevant col for testing purposes\n",
        "        df['relevant'] = [random.choice([0, 1, 2, 3, 4, 5]) for _ in range(len(df))]\n",
        "        relevance_scores.append(retriever_evaluation.ndcg_at_k(list(df['relevant']),k))\n",
        "    experiment_1_mean_normalised_discounted_cumulative_gain_res[f'bm25_{bm25_val}_faiss_{faiss_val}'] = np.mean(relevance_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5shPg3SE8OQ",
        "outputId": "ab161c7c-867f-4760-c977-c05feeaf2a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best weightage for the mean normalised discounted cumulative gain using score relevance is:\n",
            "Weightage with bm25: 0.3, faiss: 0.7 with a value of 0.7759726857883613\n"
          ]
        }
      ],
      "source": [
        "max_value_map = max(experiment_1_mean_normalised_discounted_cumulative_gain_res.values())\n",
        "best_maps = {key: value for key, value in experiment_1_mean_normalised_discounted_cumulative_gain_res.items() if value == max_value_map}\n",
        "print('The best weightage for the mean normalised discounted cumulative gain using score relevance is:')\n",
        "for k,v in best_maps.items():\n",
        "    bm25_weight = k.split('_')[1]\n",
        "    faiss_weight = k.split('_')[-1]\n",
        "    print(f'Weightage with bm25: {bm25_weight}, faiss: {faiss_weight} with a value of {v}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LEH8AQNE8OQ"
      },
      "source": [
        "### **Estimated Context Recall with RAGAS**\n",
        "\n",
        "Calculate using\n",
        "- Reference/GT answer\n",
        "- Retrieved context results\n",
        "\n",
        "To estimate context recall from the Reference/GT answer, the Reference/GT answer is broken into claims\n",
        "\n",
        "Each claim in the Reference/GT answer is analysed by an LLM to determine if it can be attributed to the retrieved context or not\n",
        "\n",
        "```\n",
        "context_recall = number of reference claims that can be attributed to the retrieved context / number of reference claims\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UESf2hNPE8OQ"
      },
      "source": [
        "**Extract the questions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08DfdVnvE8OQ"
      },
      "outputs": [],
      "source": [
        "# From Retrieval Experiment 1 and 2, save questions to a list\n",
        "question_1 = \"best food eat Finland\"\n",
        "question_2 = \"best food eat Iceland\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwCs-ig3E8OQ"
      },
      "source": [
        "**Fill in ground truth answers for each question**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGNXOJDsE8OQ"
      },
      "outputs": [],
      "source": [
        "question_1_gpt_answer = \"\"\"\n",
        "Finland's culinary traditions offer a rich array of flavors, reflecting its natural resources and cultural heritage. Here are some quintessential Finnish dishes to experience:\n",
        "\n",
        "Karjalanpiirakka (Karelian Pie)\n",
        "Originating from the Karelia region, these rye crust pastries are traditionally filled with rice porridge and often topped with egg butter. They are a beloved Finnish snack, commonly enjoyed across the country.\n",
        "\n",
        "Ruisleipä (Rye Bread)\n",
        "A staple in Finnish cuisine, this dense and dark bread is made from sourdough rye. It's typically enjoyed with butter, cheese, or cold cuts, and forms an essential part of daily meals.\n",
        "\n",
        "Kalakukko\n",
        "Hailing from the Savonia region, this traditional dish consists of fish (commonly perch or salmon) and pork baked inside a thick rye bread crust, creating a hearty and portable meal.\n",
        "\n",
        "Poronkäristys (Sautéed Reindeer)\n",
        "A specialty from Lapland, this dish features thinly sliced reindeer meat sautéed with onions and butter, typically served with mashed potatoes and lingonberry jam.\n",
        "\n",
        "Leipäjuusto (Bread Cheese)\n",
        "Also known as 'squeaky cheese' due to its texture, this mild cheese is often warmed and served with cloudberry jam, offering a unique combination of flavors.\n",
        "\n",
        "Lohikeitto (Salmon Soup)\n",
        "A creamy soup made with fresh salmon, potatoes, leeks, and dill, providing a comforting and flavorful experience, especially during colder months.\n",
        "\n",
        "Mustikkapiirakka (Blueberry Pie)\n",
        "This traditional dessert features wild Finnish blueberries baked into a pie, often enjoyed with vanilla sauce or ice cream.\n",
        "\n",
        "Exploring these dishes will provide a genuine taste of Finland's rich culinary heritage.\n",
        "\"\"\"\n",
        "\n",
        "question_2_gpt_answer = \"\"\"\n",
        "Iceland's culinary scene offers a rich tapestry of traditional dishes that reflect its unique heritage and natural resources. Here are some quintessential Icelandic foods to experience:\n",
        "\n",
        "Pylsur (Icelandic Hot Dog)\n",
        "A blend of lamb, pork, and beef, served in a soft bun with toppings like ketchup, sweet mustard, remoulade, and both raw and crispy fried onions. A popular spot to try this is Bæjarins Beztu Pylsur in Reykjavík, renowned for its delicious hot dogs.\n",
        "\n",
        "Plokkfiskur (Fish Stew)\n",
        "A hearty mix of white fish (such as cod or haddock), potatoes, onions, and béchamel sauce. This comforting dish showcases Iceland's rich fishing traditions.\n",
        "\n",
        "Hangikjöt (Smoked Lamb)\n",
        "Traditionally smoked over birch or dried sheep dung, this lamb is typically served thinly sliced with flatbread or potatoes, especially during festive seasons.\n",
        "\n",
        "Kjötsúpa (Lamb Soup)\n",
        "A nourishing soup made with lamb, root vegetables, and herbs, offering warmth during Iceland's colder months.\n",
        "\n",
        "Skyr\n",
        "A thick, creamy dairy product similar to yogurt but technically a cheese. It's enjoyed plain or with added flavors like berries and is a staple in Icelandic diets.\n",
        "\n",
        "Harðfiskur (Dried Fish)\n",
        "Wind-dried fish, often cod or haddock, served with salted butter. This protein-rich snack has been a traditional staple for centuries.\n",
        "\n",
        "Kleinur\n",
        "A twisted doughnut-like pastry, deep-fried and mildly sweet, commonly enjoyed with coffee.\n",
        "\n",
        "For a contemporary twist on traditional Icelandic cuisine, consider dining at Dill in Reykjavík. As the first Icelandic restaurant awarded a Michelin star, Dill offers innovative dishes that highlight local ingredients.\n",
        "\n",
        "Exploring these dishes will provide a genuine taste of Iceland's culinary heritage.\n",
        "\"\"\"\n",
        "\n",
        "qna = {\n",
        "    question_1: question_1_gpt_answer,\n",
        "    question_2: question_2_gpt_answer\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o-y9QBuE8OQ"
      },
      "source": [
        "**Use RAGAS library to calculate estimated context recall**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "llm = ChatGroq()\n",
        "context_recall = LLMContextRecall(llm=LangchainLLMWrapper(llm))"
      ],
      "metadata": {
        "id": "JSmXIIUJVClv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_1_binary_relevance_folder = os.path.join(experiment_folder,'binary_relevance')\n",
        "# Initialise dictionaries: { 'bm25_bm25weight_faiss_faiss_weight' = average estimated context recall}\n",
        "experiment_1_estimated_context_recall = {}\n",
        "# For each bm25 weight and faiss weight combination,\n",
        "# Calculate the context recall over all the queries\n",
        "for f_name in os.listdir(experiment_1_binary_relevance_folder):\n",
        "    f_name_split = f_name.split('_')\n",
        "    bm25_val = f_name_split[3]\n",
        "    faiss_val = f_name_split[5]\n",
        "    fp = os.path.join(experiment_1_binary_relevance_folder, f_name)\n",
        "    full_df = pd.read_csv(fp)\n",
        "    df_split = [group for query, group in full_df.groupby('query')]\n",
        "    context_recall_scores = []\n",
        "    # For each query, calculate the estimated context recall using the retrieved contexts\n",
        "    for df in df_split:\n",
        "      question = df['query'].iloc[0]\n",
        "      reference = qna[question]\n",
        "      contexts = list(df['retrieved_doc'])\n",
        "      sample = SingleTurnSample(\n",
        "          user_input=question,\n",
        "          response=\"blank\",\n",
        "          reference=reference,\n",
        "          retrieved_contexts=contexts,\n",
        "      )\n",
        "      context_recall_scores.append(await context_recall.single_turn_ascore(sample))\n",
        "      print(context_recall_scores[-1])\n",
        "    experiment_1_estimated_context_recall[f'bm25_{bm25_val}_faiss_{faiss_val}'] = np.mean(context_recall_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHRsfkRnNt_A",
        "outputId": "37aac677-f787-4293-91cc-b0056d493d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1111111111111111\n",
            "0.0\n",
            "0.1111111111111111\n",
            "0.0\n",
            "0.75\n",
            "0.3333333333333333\n",
            "0.1111111111111111\n",
            "0.0\n",
            "0.75\n",
            "0.3333333333333333\n",
            "0.1111111111111111\n",
            "0.0\n",
            "0.1111111111111111\n",
            "0.0\n",
            "0.75\n",
            "0.3333333333333333\n",
            "0.75\n",
            "0.3333333333333333\n",
            "0.5\n",
            "0.1111111111111111\n",
            "0.75\n",
            "0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_value_map = max(experiment_1_estimated_context_recall.values())\n",
        "best_maps = {key: value for key, value in experiment_1_estimated_context_recall.items() if value == max_value_map}\n",
        "print('The best weightage for the estimated context recall:')\n",
        "for k,v in best_maps.items():\n",
        "    bm25_weight = k.split('_')[1]\n",
        "    faiss_weight = k.split('_')[-1]\n",
        "    print(f'Weightage with bm25: {bm25_weight}, faiss: {faiss_weight} with a value of {v}')"
      ],
      "metadata": {
        "id": "FmtaQ0shVJ2T",
        "outputId": "ecb47824-b4d8-4f32-9214-e9c8c486095f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best weightage for the estimated context recall:\n",
            "Weightage with bm25: 0.6, faiss: 0.4 with a value of 0.5416666666666666\n",
            "Weightage with bm25: 0.9, faiss: 0.1 with a value of 0.5416666666666666\n",
            "Weightage with bm25: 1.0, faiss: 0.0 with a value of 0.5416666666666666\n",
            "Weightage with bm25: 0.8, faiss: 0.2 with a value of 0.5416666666666666\n",
            "Weightage with bm25: 0.7, faiss: 0.3 with a value of 0.5416666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOgYMXiZaraL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}