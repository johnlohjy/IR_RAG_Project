{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 3: Query Re-writing/Query Expansion for Generation**\n",
        "\n",
        "Decomposition is a query re-writing/query expansion technique that focuses on decomposing a question into a set of subquestions.\n",
        "\n",
        "This is applicable and effective for our use case as users planning a holiday tend to string together many requests in a single query. By breaking down a large queries into sub-queries, the retriever can retrieve more relevant documents to each sub-query and therefore, support the LLM in answering the whole query better"
      ],
      "metadata": {
        "id": "NpN7djOVwluU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade bitsandbytes langchain langchain-community langchain-huggingface transformers beautifulsoup4 faiss-gpu rank_bm25 lark qdrant-client langchain-chroma"
      ],
      "metadata": {
        "id": "3nBwytexAOMi",
        "outputId": "8fdbdf99-1fca-4abd-b174-bf8fd52ca113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "import torch\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import re\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import hub\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "FBUuQT4-i8rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO: Use the full data and a number of queries to test if recursive and individual answering improve the answers that the LLM gives**\n",
        "- How to compare the answers?\n",
        "- Incase the nodel is hallucinating, we need to add citations such that our performance is comparable"
      ],
      "metadata": {
        "id": "1PFqk5r5oyOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple experiment example data\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"The best hikes in Norway include the Reinebringen hike in the Lofoten islands. At a modest 448 meters high, Reinebringen is far from one of the highest peaks on the Lofoten islands. Yet this is more than made up for by the iconic view from the summit of Reine. It is not suitable for winter! Also, the trail can be quite demanding as the steps are quite steep.\",\n",
        "        metadata={\"activity\": 'Hiking', \"country\": 'Norway'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Unique hike that can be done are volcanic hikes which can be done in Iceland. It is recommended to go with a tour of experienced people!\",\n",
        "        metadata={\"activity\": 'Hiking', \"country\": 'Iceland'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Popular food in Norway is seafood! The best seafood in the Nordic region can be found in Norway. The seafood is freshly caught from the arctic ocean. Popular choices include the famous norwegian salmon. Other delicacies include whale steak!\",\n",
        "        metadata={\"activity\": 'Food', \"country\": 'Norway'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The famous street food of Iceland is the Hotdog! It is called the Baejarins Beztu Pylsur hot dog is made of a mix of lamb, beef and pork. Other delicacies of iceland include Fish and Chips as well as Tommi's burger.\",\n",
        "        metadata={\"activity\": 'Food', \"country\": 'Norway'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Transportation within Reykjavik is fairly convenient as there is a public bus service called BSI. All you need to do is to download their mobile app, follow the instructions, and you're good to go. Transportation to places outside Reykjavik however requires a car. Some options include car rentals as well as booking bus tours.\",\n",
        "        metadata={\"activity\": 'Transportation', \"country\": 'Iceland'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Finland is easily accessible with its HSL public transportation services where all you need to do is to download a mobile app and follow the instructions.\",\n",
        "        metadata={\"activity\": 'Transportation', \"country\": 'Iceland'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Finland is known for its snowy-like landscape and captivating auroras. One of the best places to stay is the Glass huts in Skyfire village in Rovaniemi, Lapland where you can admire the beautiful northern lights and snowy landscape. The village has its very own restaurant called Sky Huts Restaurant and Bar which offers tailor-made menus by a professional chef using local ingredients.\",\n",
        "        metadata={\"activity\": 'Accomodation', \"country\": 'Finland'},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A nice place to stay in Norway is the Lofoten Islands, in particlar Unstad which provides a breathtaking view of the mountain valley, ocean, and if you're lucky, northern lights.\",\n",
        "        metadata={\"activity\": 'Accomodation', \"country\": 'Norway'},\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "ihQj1CZhAWZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Decomposition template used by the LLM to help break a question into sub questions\n",
        "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
        "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
        "Generate multiple search queries related to: {question} \\n\n",
        "Output (3 queries numbered 1 to 3, each on a new line, where each query ends with '?'):\"\"\"\n",
        "\n",
        "prompt_decomposition = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "ioBgd3TcyV1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(\n",
        "      pipeline=pipeline(\n",
        "        model=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "        task=\"text-generation\",\n",
        "        temperature=0.2,\n",
        "        do_sample=True,\n",
        "        repetition_penalty=1.1,\n",
        "        max_new_tokens=400,\n",
        "        device_map=\"auto\"\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "id": "PQoxvCAhAWGJ",
        "outputId": "904c5971-e41f-4c55-ed87-901d263d1108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "53d3c5a073d24b05b470d62f7da71e48",
            "86f0d2bfa0b94ac0b01e62137a11e172",
            "626e8bf902e541a592c309b9d1b11f80",
            "479bd5150afc4e0fa2329c070cb2d701",
            "c7b2e1696de44a3eb725e660174793d0",
            "4c57b4ebe6144051b516be975e84d8f5",
            "7bed6e2a02794d1094d4ab1c322a9bd8",
            "6094fb20791444cf9cb6e1ded9184822",
            "e59aee4b020f474a84e67f4a9db092cb",
            "ac008d92445d4e8a8362fb31b08ffab5",
            "22da4a13c0ab43c5a315110aaa2d7160",
            "457a2ef3767a476a930be82bd9217e39",
            "431a216d785e4028afefeb8c999136b6",
            "966e6f271184435bbf4eaac107361188",
            "1fd7698a5ba94e4f9c68d7a1cdd2c260",
            "83692f3f7fa64770b4042ab5636fb407",
            "b0ee7882fd30431db6f7174300886dfa",
            "ebc6a6a7d6d24c35820b357506621028",
            "96cf48d0bc5c47fdb72be6d92e0e9d23",
            "ad0206c650374ce7afa7125877c45641",
            "ee2a4e994808440fb21702bd09cce3a4",
            "6dad753ee15b48dc8852eeace48c4ea8",
            "b469439d4f2b494aa75ca992ed367000",
            "28e48c23dd7b414b89e1d1ab304fa9c5",
            "f9e5689efd5047f48bf2cce364abb4d0",
            "a37a5de8ce184f94ba6fe64ad37357c9",
            "109ccd652f244880a5e2f40fd99454e8",
            "3685692537f04f709214a752325e23c4",
            "9b8afb3fea884b839871e1001aa0c7f0",
            "da52ada1bd17465296233719f7d1c0e1",
            "c4dc4d69eab341b2bc3aa617d8601928",
            "58a72a37e92a413a8de01ac1358bbc7e",
            "347a20f14bac4818bf5fbde9aae61a80",
            "6acae4238abc46c5a5376b21d52f2065",
            "c7b41ab3f6fd4ecdbf5ae66bac9b91dc",
            "72649cd49a1443a998a649891ed588aa",
            "2feb951383c744c4882337e8af79b474",
            "f770951e409543e4882d52efe39d8cc2",
            "eb9e1f838777488da21571d571349709",
            "3fb14fe85ca147c2afa8249ed6f2bad0",
            "91cd66fcf7cb4c34bc1adece17eee4a0",
            "709397242d9741038f9feaff0dfebe68",
            "9f95279460d8457083b131672c26ac2d",
            "19f2b9ee6d504f9b8d4d34403654d184",
            "01deba13df6d40b08e93f8d57012383e",
            "fc16e83798f64f7f8f58923d02be6dbf",
            "305f114c02ec4b249f547ab2d1f813cc",
            "695bd81bfda44842afc538ec42431425",
            "2c136c4a8192421f84bf6abd670b7180",
            "52f5df0206de477bb67ac361ae25b43a",
            "6032200aad144f1faab47a3464f065fb",
            "6dff294fb82f479ab3e645f1e76efefa",
            "e3870722bbd040ae8395c0ba719360c6",
            "c1a8e09652924a548fb62621f0b64405",
            "2465069c422b44e992fc5a6b964ab8a3",
            "0809da0f80b44355bfba7bd452fe5dd1",
            "8bee357a2f0045df9cad25eabf60526f",
            "6d6416a259f0486ea638e1413f6370ec",
            "a1deb07c952f462591eecbb374b29104",
            "5910117c0b2c427fbeef0647cc14b11a",
            "974573c541d2471886c328c5446dfde8",
            "13771a1cfb0f42d797cc6a27508992fe",
            "080b382cd1384e29841bf2fad9d2e98c",
            "a1fb6eed3d3e4bb4a1c9d14991c611e7",
            "ffc254f72a9240f8a25a9263553ade6d",
            "fb875b490a4b4d3094bb3d7684d51691",
            "4b6cb2e66219460d96ec1f8864fe983d",
            "1ceb60be052c4291a3222195153a42e9",
            "137875bdf487400697fd429664464230",
            "9abe3ec32c9543ddbc5a0b9339540a24",
            "a4499d4ad3e64c07a2b509123ae999cc",
            "5e04cab6cbad465298ec97611d4c1bc7",
            "83b05350174b496bb523503d1b9dae87",
            "a6c05d4eb73e47eeb9c40f493a4952e3",
            "7327aaf802d14e26906c63da5339685f",
            "14f3ad89f6a04c05bd226ba87eb21268",
            "5a5986bf74144a368c1a3bb349b3bf17",
            "e6463d6c17204f0a8c22e1b5cd6467df",
            "2b365dfade39413fa4dd2fcbef8fbe85",
            "eb8865ce40b44b89adf007b47f99b8de",
            "42049e9b45894a28b1c1f6887572ccbc",
            "0ea4ff887f744b6392daa4eb50cb8921",
            "35be45dfb75249b4877e8a53979da079",
            "f42440c7ec7345f59c069b156bfc5aef",
            "2d464f1625484dec949a90ccb0b1f158",
            "1aea652e4f8f4aa2a08ec37167e5b407",
            "3d5a603d1d424f43ae5835dca35c612c",
            "ff2092b6d5614a49abd9c039411ef835",
            "f92257732fb24ae5a6bfe29b80df7b13",
            "df08da78b9eb4eb289ab31546a4739c6",
            "265fe4729e6a46f29287797ace40af33",
            "5084f3a78634422c9a2eba1643e262ca",
            "bfd341cfe30d4d42a6d6cff2b0d32712",
            "d81e7574bba84e85a9fb686781c873e5",
            "5ee0822ca3804317b5580cab86805a54",
            "51baa248a8ee4199847f191d8f35e9ef",
            "3a56de463f1a4eeab7f8e122e2ebf631",
            "03dcf0a6ebdd4321b104711f2cd54414",
            "b9e212a314574a62ae17e3a7a910b422",
            "aa3f36bae0ec4a58ab89158df4c6d4c9",
            "82b39dc68a0f452da5d5643033a47e8f",
            "ae536226bac74dee91e33960e20b7643",
            "a268376e862a435f9963e3a389488829",
            "9eaa8149873745138050178879f53a62",
            "d4575b43445e44be93e1a70814a31901",
            "3ef22ac385374514b1f478f0398224dd",
            "4b4d76621cb44919a095375a98413ab2",
            "449f92de5d004023b7a52afdfce5937e",
            "628ab41941604d0faf78dc052d4f8155",
            "eb04f983bc1749d29314b5d7bdf62680",
            "ea9480fc79214eb89dd91c12abb16290",
            "b2c753443cac417383a6dae0189aba77",
            "0123e99c9b5941f79b6ea313b4e0304b",
            "4d9a21ea12314ca1bef3d71f9432ffa6",
            "191d7044f910465a83a05167ba2932f5",
            "7c38e68b61e14559b7ff7936f757bbca",
            "5d3cf9f6bd194de880a0b34c58914423",
            "eae56807669140ed8d8b8c941d2be740",
            "61db220965b948df839c4b578287023f",
            "c8b34bdf70af48359e32fc37f4cd0770",
            "d9664a5ace3e40579eee904bed99c320"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53d3c5a073d24b05b470d62f7da71e48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "457a2ef3767a476a930be82bd9217e39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b469439d4f2b494aa75ca992ed367000"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6acae4238abc46c5a5376b21d52f2065"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01deba13df6d40b08e93f8d57012383e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0809da0f80b44355bfba7bd452fe5dd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b6cb2e66219460d96ec1f8864fe983d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6463d6c17204f0a8c22e1b5cd6467df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f92257732fb24ae5a6bfe29b80df7b13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa3f36bae0ec4a58ab89158df4c6d4c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea9480fc79214eb89dd91c12abb16290"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom function to clean the sub-questions output by the LLM\n",
        "def clean_questions(questions):\n",
        "  questions = questions.strip()\n",
        "  questions = questions.split('\\n')\n",
        "  questions_list = []\n",
        "  for i in range(3):\n",
        "    questions_list.append(questions[i].split('?')[0] + '?')\n",
        "  return questions_list\n",
        "\n",
        "generate_queries_decomposition = ( prompt_decomposition | llm.bind(skip_prompt=True) | StrOutputParser() | clean_questions)"
      ],
      "metadata": {
        "id": "zUOTwsxvwvEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Query 1 for Decomposition Approach**\n",
        "- Might need to put all the queries in a list and run a for loop to run a function to output the results for comparison"
      ],
      "metadata": {
        "id": "ISATFGYEj3Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_query_1 = \"When is the best time to go Finland and what is there to do\""
      ],
      "metadata": {
        "id": "pbdsYx8ekD3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>Decompsition of a question into sub-questions</u>"
      ],
      "metadata": {
        "id": "PEYEfrh3sa4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the decompsition template and break down the questions into sub questions using the prompt decompsition pipeline\n",
        "questions = generate_queries_decomposition.invoke({\"question\":test_query_1})"
      ],
      "metadata": {
        "id": "9oHWZOyqkHz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions"
      ],
      "metadata": {
        "id": "8n6kubTdHbnF",
        "outputId": "d62f1f50-b541-4fb4-f173-a823aee1348c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1) when is the best time to visit finland for tourism?',\n",
              " '2) what activities are available in finland during different seasons?',\n",
              " '3) how does weather affect tourist attractions in finland?']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the FAISS retriever\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "index = faiss.IndexFlatL2(len(embeddings_model.embed_query(\"hello world\")))\n",
        "faiss_vector_store = FAISS(\n",
        "    embedding_function=embeddings_model,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")\n",
        "faiss_vector_store.add_documents(docs)\n",
        "retriever = faiss_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # num docs to return from FAISS"
      ],
      "metadata": {
        "id": "GqsJjnHmEhj7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "79961d6e240942518afa759dadff838d",
            "d7fa39c3f38044c19ab556fb588e4d6e",
            "5720e276a15e4882827358fa938f947f",
            "078859a9359f44c6b9c5992f698effec",
            "5d36e5551fea4cb8a95d8269e0ee434d",
            "18c56a4c2cd543a9a67ba116d3b3c34a",
            "28f03487ca6643d4bce753743bba544e",
            "ee5b07410d7c4508a2eb72c4b8d5811b",
            "568aad886de54ae2b47b34cf9d5f7ef2",
            "c59e599804804cada5a0d62fbcfcb734",
            "775460dd686644a5ab9e4261f5911ff5",
            "b4df8e9a3a774a9ba5615211bebe3c76",
            "dcc67640f76848bbb334343d96b8eda9",
            "f01cabe09d9a4e2aa411f402763025c8",
            "09b99aa142de47cab54b25478e1d85e9",
            "29d69e32bd42417bad4bf0c4117c11f1",
            "987f0caf12074418b68fce431f16c87a",
            "5307506d7d3c4bbbb5a00169b482d6a6",
            "0bbb0012a74b4e48a1c7ba03d71f5586",
            "4c5b219837a148078804072a2ac1d04f",
            "60c7ed623d8b4ae1968e7bc8c0051135",
            "a50aef6a09084667bc6b4ec5e2ed9399",
            "c14197671d0544e68e658cb3d89c1fd3",
            "b457313472654d4899932b86a56e7c96",
            "0c1131d723aa40b5a7588b3262482ed9",
            "d7f96e3d000046dc81ea329b84cb1bbf",
            "9b4edcab7ae4455db969af59d7874778",
            "c6cc94e1c02343b8ae527d912172e273",
            "ee180776f64b440a9eaff3bbfc2fa1b9",
            "d21a26ef26894231bdebd832839faf3e",
            "b0211fe9274c42b298b9c7ff84b3ef31",
            "d2edaf1b658a47fb899b278ad53eb829",
            "845221b124b143f6bc8af489e5fdeadf",
            "3bdbaf88ed8a4c18a08393b7df5b959d",
            "6c8360fd44af4ab3b609dd99e1a18f41",
            "86199a3e1809444b82ffdbaca9d0df3c",
            "1f95d27230e94b3fbcc475dc88ceb077",
            "46d3507cc14e4bee955ef6877a51019b",
            "9a575e638bc34692a60a1e9c7637712c",
            "c2fc889af9084347815a7f02f4144b72",
            "f2ea4d84eaed4641a949a02c6805396b",
            "4785de0795de48fdb69a40cdd4fe524f",
            "fc7e986dc7c348e2b42ac6f260ed9f8d",
            "dec114641fe0472d8963358385a5b387",
            "3e3d3271f34247d18644bbcbfdcceeaa",
            "9b9b6153e1c54dc1a3ec825bed68b2b6",
            "8599f1d3498f45a58a7f6fc6187d59e0",
            "66ee5a260b13424d8e176dd450c91d78",
            "c91e3439db6e4b8fa9067f766c8d14a7",
            "b46837cea5d64ad4822187f1ddda0a62",
            "8b4087a0269440be91ee8f0adcf7eb22",
            "100502e813df4904a028909c89a1d877",
            "6bee378bf76548679fdb9749a4cb8447",
            "33f94b85b75247749b5ea2ae92646129",
            "ae9efe94270b459b80d2fa42678282c8",
            "370013f8a6a2489986d1b0dcc6919b62",
            "83b57f6c929245efbd7173b4b9e8da45",
            "dc40e074188b4f9c9c49b04b8b39c5ab",
            "11e2fcbea23f4439b8e902366cef3eb2",
            "746df4c9b9874a35979b2b120d51190b",
            "867c76c46ada4ed39ae202fe34a16755",
            "2fd4b030412a482eb4545d390aece607",
            "ab661b6f5a8d4294b139f113ab0c3e5e",
            "c955a897de8a4b7f972d985860ee8033",
            "0a8e1b0340e544f084f9dbab56a5931a",
            "8b90075f6b044f209eeab86a675ef65b",
            "196b77b94f2044d4a13f0b31682e19f6",
            "bb028892f3b1428fb424877e2b503daf",
            "0255d994e61e4f269caf3c6af49e4bbd",
            "06b4745a9ab7435b95c34be197e24549",
            "71e558489ff740cf81c592a707287f46",
            "0c8a32b079bc4420ac995483b99847eb",
            "f678ae29983b42908c37ab1be0e37d08",
            "d64ab97030b1472e8ce5c5e83cc72e44",
            "0978e54400d64fef974fa37e19bd926b",
            "92509126d9124b8bb610383240cdd7c5",
            "c96e986e0baf4fda9bf9df02a9d71849",
            "8bf6af88f00b4885b025a6bb73642b98",
            "449ef416b1a64e42aa727c9ab78a26f1",
            "54abea0842bc4274b48902dd12cd049d",
            "f66fb6f93e4648109ea7ed55a078fe02",
            "b01ace2ec8804afd9bedeed403dc8bb8",
            "32d579f858e040c4a620aa3d08b26462",
            "0c42b552befd4a3f8a23776907fbc568",
            "c7c1e4cd53454495bd26c46172d3be3a",
            "b70b505a713e4eceb5831e8e2ed9b541",
            "a313126e9ccb4c1192dbd444b005859a",
            "897d485c228f44c692a5595e2ea7709a",
            "903e57d20841430e9d5beb2b323f8faf",
            "2ead5d3e2e614caab87483456e57e2d3",
            "869e370b4ba94e2a8f78b5b47a2b2a99",
            "1105d098f2cb4fb383805d53b9d44b8b",
            "b8f07acccb3c4572af452cdafbf85478",
            "4433fa727ccc4dee9ff4bf4fe411f18a",
            "fb3c5fef99784fbfa95642c20070aa3f",
            "4680b6add9124836bbaca5f9d3ff71a0",
            "bf2ecc3d042546668522db81f163e1b5",
            "2a3d40380c4647df9482253acabe71cb",
            "b743d320b20c409eaa1623f5c7b2b993",
            "aa0d32305f2a4fffaea1d8c8166c4f40",
            "004afbe281534659a7136e89e13aa3c1",
            "266c8c6011194616979a397bf9b80e51",
            "e9e85d431b7d40fe9700e6fd7806546f",
            "dac5c4f6d6df48bdab59d06cdd5c30d4",
            "73eadef2958a407293fe51751e294a2e",
            "52ba7e86209b4d6eaadbbc41e61142f9",
            "b5a05b8f14564b1484241897a20aa699",
            "2b58517d1e254adba1dc5ff726e643a1",
            "3954f81a4e2f4b74b5bf17f2e1d2f012",
            "d822c3f166314ec39dfeaa2fcc1e8b4f",
            "33380222b4b64da08a20420505b34dd1",
            "1834f8da6d214924a3c85f0ae9a6fd50",
            "0e3acbffca1f4d1194a6d8f846ce59ed",
            "562afefbf8d1466b8e22114a11e53391",
            "0b964ef6c6cb44d3924c550b85b73f88",
            "716661d3a72a46aa86f66e3ebd5e34eb",
            "8692bff937da495aab26f3de1d88ab31",
            "d7a3ec861fe74b0186252edd69291a99",
            "c6810835994a4e8c806562cde08bbb3c",
            "d70a82bdea3b40e7aa46a8ab2edd3663",
            "43016a8a70b04dadbed19c498f24b1fa"
          ]
        },
        "outputId": "92a84f97-2c68-4ddc-c0f0-5acea853dccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79961d6e240942518afa759dadff838d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4df8e9a3a774a9ba5615211bebe3c76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c14197671d0544e68e658cb3d89c1fd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bdbaf88ed8a4c18a08393b7df5b959d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e3d3271f34247d18644bbcbfdcceeaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "370013f8a6a2489986d1b0dcc6919b62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "196b77b94f2044d4a13f0b31682e19f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf6af88f00b4885b025a6bb73642b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "903e57d20841430e9d5beb2b323f8faf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa0d32305f2a4fffaea1d8c8166c4f40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33380222b4b64da08a20420505b34dd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>Build the Final Answer Recursively</u>"
      ],
      "metadata": {
        "id": "xw4mPOQfAqkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Prompt template to recursively answer sub questions and build up the answers\n",
        "Might need to modify prompt to ask it to use only the context\n",
        "\n",
        "question: sub-question to be answered\n",
        "q_a_pairs: Built up question-answer pairs that might be relevant\n",
        "context: context retrieved for the current sub-question\n",
        "Idea is to recursively answer each sub-question, using the current context and building upon previous answers to provide more comprehensive responses.\n",
        "'''\n",
        "template = \"\"\"Here is the question you need to answer:\n",
        "\n",
        "\\n --- \\n {question} \\n --- \\n\n",
        "\n",
        "Here is any available background question + answer pairs:\n",
        "\n",
        "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
        "\n",
        "Here is additional context relevant to the question:\n",
        "\n",
        "\\n --- \\n {context} \\n --- \\n\n",
        "\n",
        "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
        "\"\"\"\n",
        "decomposition_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "dzVY9_CrAhpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to format a given question and answer\n",
        "def format_qa_pair(question, answer):\n",
        "    \"\"\"Format Q and A pair\"\"\"\n",
        "    formatted_string = \"\"\n",
        "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "# Initialise the q_a_pairs to be empty at first\n",
        "q_a_pairs = \"\"\n",
        "\n",
        "# For each sub-question that we decomposed from our main question earlier\n",
        "for q in questions:\n",
        "  rag_chain = (\n",
        "  # Given {\"question\":q,\"q_a_pairs\":q_a_pairs}\n",
        "  {\"context\": itemgetter(\"question\") | retriever,  # Get the context relevant to the subquestion using the retriever\n",
        "    \"question\": itemgetter(\"question\"), # Get the subquestion\n",
        "    \"q_a_pairs\": itemgetter(\"q_a_pairs\")} # Get the built up qna pairs\n",
        "  | decomposition_prompt # Pass the arguments into the template\n",
        "  | llm.bind(skip_prompt=True)\n",
        "  | StrOutputParser()) # Get the result from the LLM\n",
        "\n",
        "  # Pass our rag chain the sub question and any prev built up q_a_pairs\n",
        "  answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
        "  q_a_pair = format_qa_pair(q,answer) # Format it as sub_question, answer\n",
        "  q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair # Update/Build the q_a_pairs"
      ],
      "metadata": {
        "id": "tRqtMD7QA7Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "id": "qJVYQ6f-KOjt",
        "outputId": "d55ef7a3-f787-4276-817d-d01e93d18cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To address the question of how weather affects tourist attractions in Finland, we will consider the provided context and background information.\\n\\nFirstly, let's examine the details about accommodations in Finland:\\n\\n1. **Snow Activities**: The Glass huts in Skyfire village in Rovaniemi, Lapland are highlighted as one of the best places to stay. These glass huts provide a unique experience where tourists can observe the Northern Lights and enjoy the snowy landscape. This indicates that the presence of snow and the occurrence of the Northern Lights significantly influence the appeal and accessibility of this attraction.\\n\\n2. **Northern Lights Viewing**: The Northern Lights, also known as Aurora Borealis, are mentioned as a captivating phenomenon that draws tourists to Finland. Snowfall conditions are crucial for visibility because they create a clear sky conducive to observing the aurora. Without sufficient snow cover, the atmosphere might be too cloudy or polluted, reducing the chances of seeing the Northern Lights.\\n\\nAdditionally, the context mentions other seasonal activities influenced by weather:\\n\\n3. **Spring Activities**: Wildflower trails and bird watching are more feasible during the spring season when flowers start blooming and birds begin their migration back to Finland. However, the timing and extent of these activities depend on the weather conditions, particularly rainfall and temperature changes.\\n\\n4. **Summer Activities**: Water sports and beach activities are typically associated with warmer weather. While there are some coastal areas that offer swimming pools or outdoor pools, the overall emphasis remains on outdoor recreational activities suitable for warm climates.\\n\\n5. **Autumn Activities**: Hiking and nature walks are possible during autumn when the leaves change colors. However, the quality and duration of these activities could vary depending on the amount of precipitation and cooler temperatures.\\n\\nIn summary, the weather plays a significant role in shaping tourist attractions in Finland. Snow and the Northern Lights are highly dependent on weather conditions, while other seasonal activities benefit from favorable weather patterns. Clear skies and mild temperatures enhance the enjoyment of outdoor activities, whereas inclement weather can limit certain experiences\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>Build the Final Answer Individually</u>"
      ],
      "metadata": {
        "id": "WYTT7jaWBbFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer each sub-question individually\n",
        "# RAG prompt\n",
        "'''\n",
        "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\n",
        "'''\n",
        "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
        "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
        "    \"\"\"Perform RAG on each sub-question\"\"\"\n",
        "    # Generate the sub questions using the chain\n",
        "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
        "    # Initialize a list to hold RAG results of each sub-question\n",
        "    rag_results = []\n",
        "    for sub_question in sub_questions:\n",
        "        # Retrieve documents for each sub-question\n",
        "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
        "        # Use retrieved documents and sub-question to answer the sub question\n",
        "        answer = (prompt_rag | llm.bind(skip_prompt=True) | StrOutputParser()).invoke({\"context\": retrieved_docs,\n",
        "                                                                \"question\": sub_question})\n",
        "        # Append the answer to the sub question\n",
        "        rag_results.append(answer)\n",
        "    # Return the list of sub questions and their answers\n",
        "    return rag_results,sub_questions\n",
        "\n",
        "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
      ],
      "metadata": {
        "id": "avOg004jBdp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87043a9-7a56-4f87-8e00-08f9f4217244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "<ipython-input-38-9197ef3514dd>:32: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = retriever.get_relevant_documents(sub_question)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to format a given question and answer\n",
        "def format_qa_pairs(questions, answers):\n",
        "    \"\"\"Format Q and A pairs\"\"\"\n",
        "    formatted_string = \"\"\n",
        "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
        "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "# Format the list of sub questions and their answers from just now\n",
        "context = format_qa_pairs(questions, answers)\n",
        "\n",
        "# Prompt template to use each individual sub-question and answer, as well as the main question\n",
        "template = \"\"\"Here is a set of Q+A pairs:\n",
        "\n",
        "{context}\n",
        "\n",
        "Use these to synthesize an answer to the question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    prompt\n",
        "    | llm.bind(skip_prompt=True)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({\"context\":context,\"question\":question})"
      ],
      "metadata": {
        "id": "8Olh0GE3CZSa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "10b707fa-e61d-4a94-856b-24887786b5a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To answer your question, the best time to visit Finland for tourism is during winter months like December through February when the Northern Lights (auroras) are most visible due to long nights and cold temperatures. This period provides opportunities for activities like snowshoeing, skiing, and aurora watching. However, summer from June to August also offers unique experiences such as midnight sun and vibrant nature with activities including hiking, kayaking, and berry-picking. Additionally, there's a chance to experience the country's unique glass huts in Lapland during the winter season. Overall, both winter and summer offer distinct and memorable experiences in Finland. To get the most out of your trip, it's recommended to check local forecasts and plan accordingly based on your interests and preferences. Here’s a summary of the key points:\\n\\n- **Best Time to Visit:** Winter (December through February) for Northern Lights and snowy landscapes.\\n- **Summer Activities:** Hiking, kayaking, berry-picking, and exploring glass huts in Lapland.\\n- **General Tips:** Check weather forecasts and tailor your itinerary to maximize enjoyment of each season's unique offerings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**: To be filled in"
      ],
      "metadata": {
        "id": "fPQI0arPvLuw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goL7fLxZFicO"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}